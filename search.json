[{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://fab-algo.github.io/RSQLite.toolkit/articles/dealing_with_DSV_files.html","id":"data-interpretation-issues","dir":"Articles","previous_headings":"","what":"Data interpretation issues","title":"Dealing with DSV files","text":"dealing DSV files, one common sources issues way data represented file. Since DSV files plain text files, many conventions can used represent different data types (e.g., strings, numbers, dates, missing data, etc.). Let’s start simple example using real-world data. retrieve example files, can use package piggyback download public datasets stored RSQLite.toolkit-tests GitHub repository1. first example deal table contained “standard” CSV file (.e. text file first line containing column names, using comma separate fields’ values dot decimal separator numbers); load data new table inside SQLite database using dbTableFromDSV() function. First, download data repo: unzipping downloaded file, get DOSE_V2.10.csv file contains dataset interested . can now check number rows input file: expect 46851 records SQLite table end import process. Now connect sample database (.e. tests.sqlite): move dataset table , calling dbTableFromDSV() function specifying connection database (.e., dbcon parameter) table name (.e., table_name parameter). don’t need specify parameters CSV file structure (.e., header = TRUE, sep = \",\", dec = \".\", grp = \"\") since default values fine. understand happened need keep mind dbTableFromDSV() function calls file_schema_dsv function, guess table structure stored DSV file, calls scan function actually read file content data frame write SQLite table. functions make assumptions data stored DSV file “plain text”. end, scan function uses parameters listed following table along default values (inclued also read.table function comparison): scan read.table parameters handle data interpretation. parameters control conventions used interpret text read file: quoting: convention used include strings “special” characters preserve exact string without interpretation. Parameter: quote escaping: rule used represent characters otherwise interpreted delimiters special commands. Parameter: allowEscapes NUL characters: manage ASCII NUL characters found inside strings. Parameter: skipNul whitespace stripping: whether unwanted spaces beginning, end, middle string removed. Parameter: strip.white commenting: character used identify one line (rest line “comment” identifier) contain data ignored. Parameter: comment.char missing data: missing data represented file. Parameter: na.strings missing fields: manage rows less fields expected. Parameter: fill encoding: technical standard used represent characters binary form, ASCII, UTF-8, EBCDIC. Parameter: fileEncoding understand use parameters strongly encouraged read help pages scan function. noted default values seldom—almost never—right ones invest time better understanding strategies used data source. technical description assumptions used creating file, can follow guidelines, otherwise inspect file determine direct examination. look DSV file (especially big files) better use log file explorers avoid general purpose text editors. example, can use klogg available major operating systems. open file inspect records, understand : strings comma single quote inside, surrounded double quotes, file using specific quoting convention; missing data represented “zero-lenght” string; many strings use special characters need specific encoding system; file UTF-8 encoding used. input file used example need: explicitly force quote parameter \"\\\"\" (.e., double quote character) na.strings parameter \"\"; turn commenting option: comment.char = \"\"; tell base::scan() function input file encoded UTF-8: fileEncoding = \"UTF-8\". Now can see guessed schema correct. Let’s look first rows file schema created using parameters: file_schema_dsv() function returns list many useful information input file, including schema data frame describes columns found file (.e. name, type, size, etc.). details , please refer documentation. One point note year column modified F_year since year reserved keyword SQLite. ’s default behavior dbTableFromDSV() function dealing column names (see next section details). Now can re-run dbTableFromDSV() function specifying correct parameters interpret data input file: can see now got expected records SQLite table. can check listing tables database, fields DOSE table counting number records :","code":"library(RSQLite.toolkit) #> Loading required package: RSQLite library(\"piggyback\", quietly = TRUE) pb_download(file = \"DOSE_V2.10.zip\", dest = tempdir(),             repo = \"fab-algo/RSQLite.toolkit-tests\", tag = \"latest\")  unzip(zipfile = file.path(tempdir(), \"DOSE_V2.10.zip\"), exdir = tempdir()) dir(file.path(tempdir(), \"DOSE_V2.10\")) #> [1] \"DOSE_V2.10.csv\"        \"DoseV2p10_changes.pdf\"  data_file <- file.path(tempdir(), \"DOSE_V2.10/DOSE_V2.10.csv\") n_rows <- length(count.fields(data_file)) n_rows #> [1] 46852 dbcon <- dbConnect(RSQLite::SQLite(), file.path(tempdir(), \"tests.sqlite\")) ## do not run: error dbTableFromDSV(input_file = data_file, dbcon = dbcon, table_name = \"DOSE\") #> Error: #> ! Blocking error in dbTableFromDSV while reading data from input file. #> Original error msg: scan() expected 'an integer', got 'GRC.7_1' f_schema1 <- file_schema_dsv(input_file = data_file,                              quote = \"\\\"\", na.strings = \"\",                              comment.char = \"\", fileEncoding = \"UTF-8\") f_schema1$schema[1:8, ] #>    col_names col_names_unquoted col_types sql_types  src_names src_types #> 1    country            country character      TEXT    country      text #> 2     region             region character      TEXT     region      text #> 3      GID_0              GID_0 character      TEXT      GID_0      text #> 4      GID_1              GID_1 character      TEXT      GID_1      text #> 5     F_year             F_year   integer   INTEGER       year      text #> 6    grp_lcu            grp_lcu   numeric      REAL    grp_lcu      text #> 7        pop                pop   numeric      REAL        pop      text #> 8 grp_pc_lcu         grp_pc_lcu   numeric      REAL grp_pc_lcu      text #>   src_is_quoted #> 1         FALSE #> 2         FALSE #> 3         FALSE #> 4         FALSE #> 5         FALSE #> 6         FALSE #> 7         FALSE #> 8         FALSE dbTableFromDSV(input_file = data_file, dbcon = dbcon, table_name = \"DOSE\",                drop_table = TRUE, quote = \"\\\"\", na.strings = \"\",                comment.char = \"\", fileEncoding = \"UTF-8\") #> [1] 46851 dbListTables(dbcon) #> [1] \"DOSE\"  dbListFields(dbcon, \"DOSE\")[1:8] #> [1] \"country\"    \"region\"     \"GID_0\"      \"GID_1\"      \"F_year\"     #> [6] \"grp_lcu\"    \"pop\"        \"grp_pc_lcu\"  dbGetQuery(dbcon, \"SELECT COUNT(*) AS n_records FROM DOSE\") #>   n_records #> 1     46851"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/articles/dealing_with_DSV_files.html","id":"issues-with-column-names","dir":"Articles","previous_headings":"","what":"Issues with column names","title":"Dealing with DSV files","text":"Unfortunately, dealing DSV files, problems limited data interpretation . Another common source issues column names used input file. DSV files may contain column headers valid original context (Excel applications), names might conform SQLite’s naming conventions best practices. SQLite specific rules restrictions regarding column names, including: Must begin letter (-Z, -z) underscore (_) Can contain letters, digits (0-9), underscores (_) reserved keyword SQLite avoid special characters spaces better compatibility can find details SQLite’s naming conventions official documentation CREATE TABLE page. also interesting discussions Stack Overflow: valid table names SQLite? SQLite column name can /? SQLite table column name requirements typical problems might encounter include: Special characters: Column names containing spaces, hyphens, special characters (e.g., \"Patient-ID\", \"Test Result\", \"Cost($)\"); Reserved keywords: Column names match SQLite reserved words (e.g., \"SELECT\", \"TABLE\", \"\"); Starting numbers: Column names beginning digits (e.g., \"2025_Sales\"); Case sensitivity: SQLite case-insensitive column names, mixing cases can lead confusion; Empty duplicate names: Missing headers columns identical names. always inspect column names DSV files importing SQLite database ensure meet criteria. Failing can lead errors import process unexpected behavior querying database.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/articles/dealing_with_DSV_files.html","id":"how-rsqlite-toolkit-handles-column-names","dir":"Articles","previous_headings":"Issues with column names","what":"How RSQLite.toolkit handles column names","title":"Dealing with DSV files","text":"dbTableFromDSV() function2 offers built-mechanism handle problematic column names importing data DSV files. id_quote_method parameter can set one following values: substituting characters, letters digits _ character, _ character; prefixing N_ strings starting digit; prefixing F_ strings equal SQL92 keyword. SINGLE_QUOTES encloses string single quotes. SQL_SERVER encloses string square brackets. MYSQL encloses string back ticks. default value DB_NAMES. actually happens ensure valid unique column names, dbTableFromDSV() function calls file_schema_dsv() function turn calls format_column_names() function, passing column names read DSV file, selected id_quote_method unique_names = TRUE parameter, ensure column names unique. satisfied way column names handled, can always manually specify column names used SQLite table using col_names parameter dbTableFromDSV() function.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/articles/dealing_with_DSV_files.html","id":"example","dir":"Articles","previous_headings":"Issues with column names","what":"Example","title":"Dealing with DSV files","text":"Let’s create simple example demonstrate behavior; use DSV file problematic column names download RSQLite.toolkit-tests repository. Now can inspect column names used input file: src_names column contains original column names found input file. can see, problematic column names, Author(s) ID, Document Title, Funding Text, Art. ., etc. col_names column contains transformed column names using DB_NAMES method (.e., default value id_quote_method parameter). Comparing two columns, can see characters replaced _ character, spaces replaced _, names prefixed F_ avoid conflicts SQLite reserved keywords (e.g., Year). Now let’s see column names handled using SQL_SERVER method: can see, now column names enclosed square brackets ([ ]) make valid SQLite identifiers. quoting convention allows use special characters spaces column names without causing issues database operations. can test creating new table database using quoting method:","code":"library(\"piggyback\", quietly = TRUE) pb_download(file = \"Blockchain_Banking_Scopus_Dataset_2015_2025.zip\",             dest = tempdir(), repo = \"fab-algo/RSQLite.toolkit-tests\",             tag = \"latest\")  unzip(zipfile = file.path(tempdir(),                           \"Blockchain_Banking_Scopus_Dataset_2015_2025.zip\"),       exdir = file.path(tempdir(), \"Blockchain\")) dir(file.path(tempdir(), \"Blockchain\")) #> [1] \"Blockchain_Banking_Scopus_Dataset_2015_2025.csv\"  data_file <- file.path(tempdir(),                        \"Blockchain/Blockchain_Banking_Scopus_Dataset_2015_2025.csv\") # nolint f_schema2 <- file_schema_dsv(input_file = data_file,                              quote = \"\\\"\", na.strings = \"\",                              comment.char = \"\", fileEncoding = \"UTF-8\")  f_schema2$schema[1:10, ] #>            col_names col_names_unquoted col_types sql_types         src_names #> 1            Authors            Authors character      TEXT           Authors #> 2  Author_full_names  Author_full_names character      TEXT Author full names #> 3        Author_s_ID        Author_s_ID character      TEXT      Author(s) ID #> 4              Title              Title character      TEXT             Title #> 5             F_Year             F_Year character      TEXT              Year #> 6       Source_title       Source_title character      TEXT      Source title #> 7             Volume             Volume character      TEXT            Volume #> 8              Issue              Issue character      TEXT             Issue #> 9            Art_No_            Art_No_ character      TEXT          Art. No. #> 10        Page_start         Page_start character      TEXT        Page start #>    src_types src_is_quoted #> 1       text          TRUE #> 2       text          TRUE #> 3       text          TRUE #> 4       text          TRUE #> 5       text          TRUE #> 6       text          TRUE #> 7       text          TRUE #> 8       text          TRUE #> 9       text          TRUE #> 10      text          TRUE f_schema2 <- file_schema_dsv(input_file = data_file,                              quote = \"\\\"\", na.strings = \"\",                              id_quote_method = \"SQL_SERVER\",                              comment.char = \"\", fileEncoding = \"UTF-8\")  f_schema2$schema[1:10, ] #>              col_names col_names_unquoted col_types sql_types         src_names #> 1            [Authors]            Authors character      TEXT           Authors #> 2  [Author full names]  Author full names character      TEXT Author full names #> 3       [Author(s) ID]       Author(s) ID character      TEXT      Author(s) ID #> 4              [Title]              Title character      TEXT             Title #> 5               [Year]               Year character      TEXT              Year #> 6       [Source title]       Source title character      TEXT      Source title #> 7             [Volume]             Volume character      TEXT            Volume #> 8              [Issue]              Issue character      TEXT             Issue #> 9           [Art. No.]           Art. No. character      TEXT          Art. No. #> 10        [Page start]         Page start character      TEXT        Page start #>    src_types src_is_quoted #> 1       text          TRUE #> 2       text          TRUE #> 3       text          TRUE #> 4       text          TRUE #> 5       text          TRUE #> 6       text          TRUE #> 7       text          TRUE #> 8       text          TRUE #> 9       text          TRUE #> 10      text          TRUE dbTableFromDSV(input_file = data_file,                dbcon = dbcon, table_name = \"BLOCKCHAIN_BANKING\",                quote = \"\\\"\", na.strings = \"\",                comment.char = \"\", fileEncoding = \"UTF-8\",                id_quote_method = \"SQL_SERVER\",                drop_table = TRUE) #> [1] 389 dbListTables(dbcon) #> [1] \"BLOCKCHAIN_BANKING\" \"DOSE\"  dbListFields(dbcon, \"BLOCKCHAIN_BANKING\")[1:8] #> [1] \"Authors\"           \"Author full names\" \"Author(s) ID\"      #> [4] \"Title\"             \"Year\"              \"Source title\"      #> [7] \"Volume\"            \"Issue\"  dbGetQuery(dbcon, \"SELECT COUNT(*) AS n_records FROM BLOCKCHAIN_BANKING\") #>   n_records #> 1       389 dbDisconnect(dbcon)"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/articles/dealing_with_DSV_files.html","id":"conclusions","dir":"Articles","previous_headings":"","what":"Conclusions","title":"Dealing with DSV files","text":"safely handle DSV files (avoid unexpected results) importing data SQLite database using dbTableFromDSV() function, always: inspect input file understand data represented; end, can use file_schema_dsv() function help task test different parameter settings importing data; specify correct parameters interpret data input file (.e. quote, na.strings, comment.char, fileEncoding, etc.); check column names used input file choose right strategy handle , id_quote_method parameter dbTableFromDSV() function can useful.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ludovico G. Beretta. Author, maintainer, copyright holder.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Beretta L (2026). RSQLite.toolkit: Load Data SQLite Tabular Files. R package version 0.0.4, https://github.com/fab-algo/RSQLite.toolkit.","code":"@Manual{,   title = {RSQLite.toolkit: Load Data in SQLite from Tabular Files},   author = {Ludovico G. Beretta},   year = {2026},   note = {R package version 0.0.4},   url = {https://github.com/fab-algo/RSQLite.toolkit}, }"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"rsqlitetoolkit-","dir":"","previous_headings":"","what":"Load Data in SQLite from Tabular Files","title":"Load Data in SQLite from Tabular Files","text":"RSQLite.toolkit lightweight wrapper around RSQLite package streamlined loading data tabular files (.e. text delimited files like CSV TSV, Microsoft Excel, Arrow IPC files) SQLite databases. also includes helper functions inspecting structure input files, functions simplify activities SQLite tables.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Load Data in SQLite from Tabular Files","text":"can install development version RSQLite.toolkit GitHub :","code":"# Install development version from GitHub # install.packages(\"pak\") pak::pak(\"fab-algo/RSQLite.toolkit\")"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Load Data in SQLite from Tabular Files","text":"basic examples show use core functions package load example data different tables test database:","code":"library(RSQLite.toolkit) #> Loading required package: RSQLite  dbcon <- dbConnect(RSQLite::SQLite(), file.path(tempdir(), \"tests.sqlite\"))  data_path <- system.file(\"extdata\", package = \"RSQLite.toolkit\")  ## creates the table ABALONE from a CSV file, adding the field 'SEQ' with the ## ROWID of each record through the use of the parameter 'auto_pk=TRUE' dbTableFromDSV(input_file = file.path(data_path, \"abalone.csv\"),                dbcon = dbcon, table_name = \"ABALONE\",                drop_table = TRUE, auto_pk = TRUE,                header = TRUE, sep = \",\", dec = \".\") #> [1] 4177  ## creates the table PORTFOLIO_PERF from Excel file, using the \"all period\" sheet dbTableFromXlsx(input_file = file.path(data_path,                                        \"stock_portfolio.xlsx\"),                 dbcon = dbcon, table_name = \"PORTFOLIO_PERF\",                 drop_table = TRUE,                 sheet_name = \"all period\", first_row = 2, cols_range = \"A:S\") #> [1] 63  ## creates the table PENGUINS from Feather file dbTableFromFeather(input_file = file.path(data_path, \"penguins.feather\"),                    dbcon = dbcon, table_name = \"PENGUINS\",                    drop_table = TRUE) #> [1] 333  dbListTables(dbcon) #> [1] \"ABALONE\"        \"PENGUINS\"       \"PORTFOLIO_PERF\"  dbListFields(dbcon, \"ABALONE\") #>  [1] \"Sex\"     \"Length\"  \"Diam\"    \"Height\"  \"Whole\"   \"Shucked\" \"Viscera\" #>  [8] \"Shell\"   \"Rings\"   \"SEQ\" dbListFields(dbcon, \"PENGUINS\") #> [1] \"species\"           \"culmen_length_mm\"  \"culmen_depth_mm\"   #> [4] \"flipper_length_mm\" \"body_mass_g\"       \"sex\" dbListFields(dbcon, \"PORTFOLIO_PERF\")[1:5] #> [1] \"ID\"                                    #> [2] \"Large_B_P\"                             #> [3] \"Large_ROE\"                             #> [4] \"Large_S_P\"                             #> [5] \"Large_Return_Rate_in_the_last_quarter\"  dbDisconnect(dbcon)"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"core-functions","dir":"","previous_headings":"","what":"Core Functions","title":"Load Data in SQLite from Tabular Files","text":"basic idea behind package storing data used throughout data-analysis workflow local database highly efficient effective way manage information. advantages keeping raw data metadata together database—ideally shared data model—far outweigh additional overhead maintaining structured system, also costs complexity involved importing information external files disparate formats conventions. purpose package reduce burden last point (.e., importing data) much possible set functions read data source files, create destination table (exist), store data , index , one step. core functions package therefore can used move data file database table: dbTableFromDSV() dbTableFromXlsx() dbTableFromFeather() Together , couple additional functions: dbTableFromDataFrame() dbTableFromView() handy move data intermediate data structures database tables, using logic core ones. functions share common calling template outlined following picture:  core functions require three mandatory arguments: input_file dbcon table_name default values. dbTableFromXlsx() requires three additional arguments (defaults): sheet_name, first_row, cols_range needed correctly locate dataset imported inside Excel file. details parameters functions’ behaviour available standard function documentation accessible R’s help system. Anyway, careful default values arguments, especially importing delimiter separated values text files: default values input data interpretation arguments seldom right ones. also true default values functions actually used package read data files, : base::scan() reading DSV files; openxlsx2::wb_to_df() reading Xlsx files; arrow::FeatherReader() reading Feather files. Given high variability data can stored DSV Excel files, always possibility passing specific parameters -listed functions special argument “...”. help using additional arguments dbTableFromDSV(), along base::scan(), can read vignette “Dealing DSV files” part package. first section document describes use base::scan() arguments read complex DSV files. second section detailed description issues related column names used data file corresponding identifiers SQLite table’s fields. second section vignette can helpful also importing data Xlsx Feather files.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"file-schema-inspection-functions","dir":"","previous_headings":"","what":"File Schema Inspection Functions","title":"Load Data in SQLite from Tabular Files","text":"loading data SQLite database, RSQLite.toolkit provides specialized functions inspect structure schema input files without loading entire dataset memory. particularly useful large files need understand data types column structure importing. package includes three schema inspection functions: file_schema_dsv() - delimiter-separated values files (CSV, TSV, etc.) file_schema_feather() - Arrow Feather files file_schema_xlsx() - Microsoft Excel files","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"purpose-and-benefits","dir":"","previous_headings":"File Schema Inspection Functions","what":"Purpose and Benefits","title":"Load Data in SQLite from Tabular Files","text":"functions serve several important purposes: Memory Efficiency: Preview large files without loading completely memory Data Type Detection: Automatically infer (least try ) R SQLite data types column Column Name Formatting: Show column names formatted SQLite compatibility Import Planning: Help understand structure using main dbTableFrom*() functions Troubleshooting: Identify potential issues file structure, encoding, formatting","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"what-they-return","dir":"","previous_headings":"File Schema Inspection Functions","what":"What They Return","title":"Load Data in SQLite from Tabular Files","text":"three functions return data frame following key columns: col_names: Column names applying SQLite formatting rules col_names_unquoted: Unquoted column names (different col_names) col_types: Inferred R data types column sql_types: Corresponding SQLite data types src_names: Original column names appear source file src_types: Source data types (varies file format)","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"usage-examples","dir":"","previous_headings":"File Schema Inspection Functions","what":"Usage Examples","title":"Load Data in SQLite from Tabular Files","text":"","code":"library(RSQLite.toolkit)  data_path <- system.file(\"extdata\", package = \"RSQLite.toolkit\")  file_schema_dsv(input_file = file.path(data_path, \"abalone.csv\"),                 header = TRUE, sep = \",\", dec = \".\")$schema[, c(1, 3:7)] #>   col_names col_types sql_types src_names src_types src_is_quoted #> 1       Sex character      TEXT       Sex      text         FALSE #> 2    Length   numeric      REAL    Length      text         FALSE #> 3      Diam   numeric      REAL      Diam      text         FALSE #> 4    Height   numeric      REAL    Height      text         FALSE #> 5     Whole   numeric      REAL     Whole      text         FALSE #> 6   Shucked   numeric      REAL   Shucked      text         FALSE #> 7   Viscera   numeric      REAL   Viscera      text         FALSE #> 8     Shell   numeric      REAL     Shell      text         FALSE #> 9     Rings   integer   INTEGER     Rings      text         FALSE  file_schema_feather(input_file = file.path(data_path,                                            \"penguins.feather\"))[, c(1, 3:6)] #>           col_names col_types sql_types         src_names src_types #> 1           species character      TEXT           species      utf8 #> 2  culmen_length_mm    double      REAL  culmen_length_mm    double #> 3   culmen_depth_mm    double      REAL   culmen_depth_mm    double #> 4 flipper_length_mm    double      REAL flipper_length_mm    double #> 5       body_mass_g    double      REAL       body_mass_g    double #> 6               sex character      TEXT               sex      utf8"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"when-to-use-these-functions","dir":"","previous_headings":"File Schema Inspection Functions","what":"When to Use These Functions","title":"Load Data in SQLite from Tabular Files","text":"importing large files understand structure debugging import issues identify data type conflicts data documentation understand file contents without opening working unfamiliar datasets explore column names types verify column naming conventions work SQLite schema functions use parameters corresponding dbTableFrom*() functions, making easy test refine import settings committing full data load.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"database-utility-functions","dir":"","previous_headings":"","what":"Database Utility Functions","title":"Load Data in SQLite from Tabular Files","text":"Beyond core data import capabilities, RSQLite.toolkit provides two utility functions simplifying database operations: dbExecFile() - Execute SQL statements text files dbCopyTable() - Copy tables SQLite databases","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"dbexecfile-batch-sql-execution","dir":"","previous_headings":"Database Utility Functions","what":"dbExecFile: Batch SQL Execution","title":"Load Data in SQLite from Tabular Files","text":"dbExecFile() function allows execute multiple SQL statements stored text file, making ideal : Database schema setup (creating tables, indexes, views) Batch data operations (updates, deletions, transformations) Database maintenance scripts (cleanup, optimization) Reproducible database workflows (version-controlled SQL scripts) Moreover, possibility read SQL statements directly text file avoids need embed long SQL instructions strings inside main R code, making source readable.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"key-features","dir":"","previous_headings":"Database Utility Functions > dbExecFile: Batch SQL Execution","what":"Key Features","title":"Load Data in SQLite from Tabular Files","text":"Comment stripping: Automatically removes SQL comments (lines starting --) Statement splitting: Separates multiple statements using semicolons (;) Parameter binding: Optional support parameterized queries Result collection: Returns results executed statement list","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"usage-examples-1","dir":"","previous_headings":"Database Utility Functions > dbExecFile: Batch SQL Execution","what":"Usage Examples","title":"Load Data in SQLite from Tabular Files","text":"","code":"library(RSQLite.toolkit)  dbcon <- dbConnect(RSQLite::SQLite(), file.path(tempdir(), \"tests.sqlite\"))  data_path <- system.file(\"extdata\", package = \"RSQLite.toolkit\") dbTableFromDSV(input_file = file.path(data_path, \"abalone.csv\"),                dbcon = dbcon, table_name = \"ABALONE\",                drop_table = TRUE, auto_pk = TRUE,                header = TRUE, sep = \",\", dec = \".\") #> [1] 4177  ## SQL file content: each statement is separated by a semicolon sql_text <- paste(\"SELECT SEX, RINGS, COUNT(*) AS NUM, AVG(LENGTH) \",                    \"AS AVG_LENGTH FROM ABALONE GROUP BY SEX, RINGS;\",                   \"SELECT SEX, round(WHOLE/0.02,0)*0.02 as WHOLE_GRP, \",                   \"COUNT(*) AS NUM, AVG(LENGTH) AS AVG_LENGTH \",                    \"FROM ABALONE GROUP BY SEX, round(WHOLE/0.02,0)*0.02;\",                   sep = \"\\n\")  sql_file <- tempfile(fileext = \".sql\") writeLines(sql_text, con = sql_file)  res <- dbExecFile(input_file = sql_file, dbcon = dbcon)  res[[1]][1:10, ] #>    Sex Rings NUM AVG_LENGTH #> 1    F     5   4  0.3237500 #> 2    F     6  16  0.4628125 #> 3    F     7  44  0.4678409 #> 4    F     8 122  0.5380328 #> 5    F     9 238  0.5746008 #> 6    F    10 248  0.5822782 #> 7    F    11 200  0.6137000 #> 8    F    12 128  0.5949219 #> 9    F    13  88  0.5814773 #> 10   F    14  56  0.5960714  res[[2]][1:10, ] #>    Sex WHOLE_GRP NUM AVG_LENGTH #> 1    F      0.08   1  0.2750000 #> 2    F      0.14   2  0.2975000 #> 3    F      0.16   1  0.3050000 #> 4    F      0.18   3  0.3483333 #> 5    F      0.20   8  0.3425000 #> 6    F      0.22   4  0.3737500 #> 7    F      0.24   2  0.3700000 #> 8    F      0.26   4  0.3775000 #> 9    F      0.28   8  0.3675000 #> 10   F      0.30   4  0.3925000  unlink(sql_file) dbDisconnect(dbcon)"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"dbcopytable-cross-database-table-operations","dir":"","previous_headings":"Database Utility Functions","what":"dbCopyTable: Cross-Database Table Operations","title":"Load Data in SQLite from Tabular Files","text":"dbCopyTable() function enables copy entire tables different SQLite database files, useful : Data archiving (moving historical data archive databases) Database splitting (distributing data across multiple files) Backup operations (creating table-specific backups) Data sharing (copying tables shared databases) Development workflows (copying production data test environments) typical scenario function becomes really useful want start new analysis workflow new environment want carry part data used previous one. function allows move whole tables SQLite database used old workflow new database, can add recent data can reuse previous results.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"key-features-1","dir":"","previous_headings":"Database Utility Functions > dbCopyTable: Cross-Database Table Operations","what":"Key Features","title":"Load Data in SQLite from Tabular Files","text":"Flexible copying: Append existing tables create new ones Index preservation: Optionally copy indexes along data Cross-database operation: Works different SQLite database files Safe operations: Option drop/recreate target tables safely","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"usage-examples-2","dir":"","previous_headings":"Database Utility Functions > dbCopyTable: Cross-Database Table Operations","what":"Usage Examples","title":"Load Data in SQLite from Tabular Files","text":"","code":"# Copy a table from one database to another dbCopyTable(   db_file_src = \"source.sqlite\",    db_file_tgt = \"backup.sqlite\",   table_name = \"sales_data\",   drop_table = TRUE,        # Recreate table if it exists   copy_indexes = TRUE       # Copy indexes too )  # Append data to existing table (no index copying) dbCopyTable(   db_file_src = \"daily_data.sqlite\",   db_file_tgt = \"master.sqlite\",    table_name = \"transactions\",   drop_table = FALSE        # Append to existing table )  # Archive old data dbCopyTable(   db_file_src = \"production.sqlite\",   db_file_tgt = \"archive_2024.sqlite\",   table_name = \"historical_sales\",   drop_table = TRUE,   copy_indexes = TRUE )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"when-to-use-these-functions-1","dir":"","previous_headings":"Database Utility Functions","what":"When to Use These Functions:","title":"Load Data in SQLite from Tabular Files","text":"Use dbExecFile() : Setting complex database schemas Running maintenance cleanup scripts Executing version-controlled SQL migrations Performing batch data transformations Need run multiple related SQL statements Use dbCopyTable() : Creating backups specific tables Moving data environments (dev/test/prod) Archiving historical data Splitting large databases smaller files Sharing specific datasets collaborators utility functions complement core data import functions providing database management capabilities often needed real-world data analysis workflows.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/index.html","id":"data-sources","dir":"","previous_headings":"","what":"Data Sources","title":"Load Data in SQLite from Tabular Files","text":"example datasets, included extdata package directory, retrieved following sources: \"abalone.csv\": Predicting age abalone physical measurements. Source link: https://archive.ics.uci.edu/dataset/1/abalone \"stock_portfolio.xlsx\": Stock portfolio performance new weighted scoring stock selection model. Source link: https://archive.ics.uci.edu/dataset/390/stock+portfolio+performance \"penguins.feather\": Palmer Archipelago’s penguins data set. Source link: https://allisonhorst.github.io/palmerpenguins/. “feather” file format dataset downloaded https://github.com/lmassaron/datasets.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/R2SQL_types.html","id":null,"dir":"Reference","previous_headings":"","what":"From R class names to SQLite data types — R2SQL_types","title":"From R class names to SQLite data types — R2SQL_types","text":"R2SQL_types() function returns character vector names SQLite data types corresponding R classes passed x parameter. class recognized, replaced TEXT data type.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/R2SQL_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"From R class names to SQLite data types — R2SQL_types","text":"","code":"R2SQL_types(x)"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/R2SQL_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"From R class names to SQLite data types — R2SQL_types","text":"x character, vector containing strings R class names.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/R2SQL_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"From R class names to SQLite data types — R2SQL_types","text":"character vector names SQLite data types.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCopyTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Copy a table from one SQLite database to another — dbCopyTable","title":"Copy a table from one SQLite database to another — dbCopyTable","text":"dbCopyTable() function can used create copy data table SQLite database another database. data can appended already existing table (name source one), new table can created. possible move also indexes source target.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCopyTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copy a table from one SQLite database to another — dbCopyTable","text":"","code":"dbCopyTable(   db_file_src,   db_file_tgt,   table_name,   drop_table = FALSE,   copy_indexes = FALSE )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCopyTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copy a table from one SQLite database to another — dbCopyTable","text":"db_file_src character, file name (including path) source database containing table copied. db_file_tgt character, file name (including path) target database table copied. table_name character, table name. drop_table logical, TRUE table target database dropped (exists) copying data. FALSE, data appended existing table target database. Defaults FALSE. copy_indexes logical, TRUE also drop_table TRUE, indexes defined source table created target table. Defaults FALSE.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCopyTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copy a table from one SQLite database to another — dbCopyTable","text":"nothing","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCreatePK.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a unique index on a table in a SQLite database — dbCreatePK","title":"Creates a unique index on a table in a SQLite database — dbCreatePK","text":"dbCreatePK() function creates UNIQUE INDEX named <table_name>_PK table specified table_name database connected dbcon. index created fields specified pk_fields argument.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCreatePK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a unique index on a table in a SQLite database — dbCreatePK","text":"","code":"dbCreatePK(dbcon, table_name, pk_fields, drop_index = FALSE)"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCreatePK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a unique index on a table in a SQLite database — dbCreatePK","text":"dbcon database connection, created dbConnect function. table_name character, name table index created. pk_fields character vector, list fields' names define UNIQUE INDEX. drop_index logical, TRUE index named <table_name>_PK dropped (exists) recreating . FALSE, check index name exists eventually stops. Default FALSE.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbCreatePK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a unique index on a table in a SQLite database — dbCreatePK","text":"nothing","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbExecFile.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute SQL statements from a text file — dbExecFile","title":"Execute SQL statements from a text file — dbExecFile","text":"dbExecFile() function executes SQL statements contained text file. function reads text input_file, strips comment lines (.e. lines beginning -- characters) splits SQL statements assuming separated ; character. list SQL statements executed, one time; results statement stored list length equal number statements.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbExecFile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute SQL statements from a text file — dbExecFile","text":"","code":"dbExecFile(input_file, dbcon, plist = NULL)"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbExecFile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute SQL statements from a text file — dbExecFile","text":"input_file file name (including path) containing SQL statements executed dbcon database connection, created dbConnect function. plist list values binded parameters SQL statements. Defaults NULL","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbExecFile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute SQL statements from a text file — dbExecFile","text":"list results returned statement executed.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDSV.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table from a delimiter separated values (DSV) text file — dbTableFromDSV","title":"Create a table from a delimiter separated values (DSV) text file — dbTableFromDSV","text":"dbTableFromDSV() function reads data DSV file copies table SQLite database. table exist, create . dbTableFromDSV() function reads data DSV file copies table SQLite database. table exist, create .","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDSV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table from a delimiter separated values (DSV) text file — dbTableFromDSV","text":"","code":"dbTableFromDSV(   input_file,   dbcon,   table_name,   header = TRUE,   sep = \",\",   dec = \".\",   grp = \"\",   id_quote_method = \"DB_NAMES\",   col_names = NULL,   col_types = NULL,   col_import = NULL,   drop_table = FALSE,   auto_pk = FALSE,   build_pk = FALSE,   pk_fields = NULL,   constant_values = NULL,   chunk_size = 0,   ... )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDSV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table from a delimiter separated values (DSV) text file — dbTableFromDSV","text":"input_file character, file name (including path) read. dbcon database connection, created dbConnect function. table_name character, name table. header logical, TRUE first line contains columns' names. FALSE, columns' names formed sing \"V\" followed column number (specified utils::read.table()). sep character, field delimiter (e.g., \",\" CSV, \"\\t\" TSV) input file. Defaults \",\". dec character, decimal separator (e.g., \".\" \",\" depending locale) input file. Defaults \".\". grp character, character used digit grouping. defaults \"\" (.e. grouping). id_quote_method character, used specify build SQLite columns' names using fields' identifiers read input file. details see description quote_method parameter format_column_names() function. Defautls DB_NAMES. col_names character vector, names columuns input file. Used override field names derived input file (using quote method selected id_quote_method). Must length number columns input file. NULL column names coming input file (quoting) used. Defaults NULL. col_types character vector classes assumed columns input file. Must length number columns input file. null, override data types guessed input file. NULL data type inferred input files used. Defaults NULL. col_import can either: numeric vector (coherced integers) columns' positions input file imported SQLite table; character vector columns' names imported. names input file (quoting id_quote_method), col_names NULL, expressed col_names vector. Defaults NULL, .e. columns imported. drop_table logical, TRUE target table dropped (exists) recreated importing data.  FALSE, data input file appended existing table. Defaults FALSE. auto_pk logical, TRUE, pk_fields parameter NULL, additional column named SEQ added table defined INTEGER PRIMARY KEY (.e. effect alias ROWID). Defaults FALSE. build_pk logical, TRUE creates UNIQUE INDEX named <table_name>_PK defined combination fields specified pk_fields parameter. effective pk_fields null. Defaults FALSE. pk_fields character vector, list fields' names define UNIQUE INDEX. Defaults NULL. constant_values one row data frame whose columns added table database. additional table columns named data frame columns, corresponding values associeted record imported input file. useful keep track additional information (e.g., input file name, additional context data available data set, ...) loading content multiple input files table. chunk_size integer, number lines \"chunk\" (.e. block lines input file). Setting value positive integer number, process input file blocks chunk_size lines, avoiding read data memory . can useful large size files. set zero, process whole text file one pass. Default zero. ... additional arguments passed base::scan() function used read input data. Please note quote parameter specified, set \"\" (.e., quoting) default.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDSV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a table from a delimiter separated values (DSV) text file — dbTableFromDSV","text":"integer, number records table_name reading data input_file.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table in a SQLite database from a data frame — dbTableFromDataFrame","title":"Create a table in a SQLite database from a data frame — dbTableFromDataFrame","text":"dbTableFromDataFrame() function reads data rectangula region sheet Excel file copies table SQLite database. table exist, create .","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table in a SQLite database from a data frame — dbTableFromDataFrame","text":"","code":"dbTableFromDataFrame(   df,   dbcon,   table_name,   id_quote_method = \"DB_NAMES\",   col_names = NULL,   col_types = NULL,   drop_table = FALSE,   auto_pk = FALSE,   build_pk = FALSE,   pk_fields = NULL )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table in a SQLite database from a data frame — dbTableFromDataFrame","text":"df data frame saved SQLite table. dbcon database connection, created dbConnect function. table_name character, name table. id_quote_method character, used specify build SQLite columns' names using fields' identifiers read input file. details see description quote_method parameter format_column_names() function. Defautls DB_NAMES. col_names character vector, names columuns imported. Used override field names derived data frame (using quote method selected id_quote_method). Must length number columns data frame. NULL column names coming input (quoting) used. Defaults NULL. col_types character vector classes assumed columns. null, override data types inferred input data frame. Must length number columns input. NULL data type inferred input used. Defaults NULL. drop_table logical, TRUE target table dropped (exists) recreated importing data.  FALSE, data input data frame appended existing table. Defaults FALSE. auto_pk logical, TRUE, pk_fields parameter NULL, additional column named SEQ added table defined INTEGER PRIMARY KEY (.e. effect alias ROWID). Defaults FALSE. build_pk logical, TRUE creates UNIQUE INDEX named <table_name>_PK defined combination fields specified pk_fields parameter. effective pk_fields null. Defaults FALSE. pk_fields character vector, list fields' names define UNIQUE INDEX. Defaults NULL.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromDataFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a table in a SQLite database from a data frame — dbTableFromDataFrame","text":"integer, number records table_name reading data data frame.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromFeather.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table from a Feather (Arrow IPC) file — dbTableFromFeather","title":"Create a table from a Feather (Arrow IPC) file — dbTableFromFeather","text":"dbTableFromFeather() function reads data Feather (Arrow IPC) file copies table SQLite database. table exist, create . dbTableFromFeather() function reads data Apache Arrow table serialized Feather (Arrow IPC) file copies table SQLite database. table exist, create .","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromFeather.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table from a Feather (Arrow IPC) file — dbTableFromFeather","text":"","code":"dbTableFromFeather(   input_file,   dbcon,   table_name,   id_quote_method = \"DB_NAMES\",   col_names = NULL,   col_types = NULL,   col_import = NULL,   drop_table = FALSE,   auto_pk = FALSE,   build_pk = FALSE,   pk_fields = NULL,   constant_values = NULL )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromFeather.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table from a Feather (Arrow IPC) file — dbTableFromFeather","text":"input_file character, file name (including path) read. dbcon database connection, created dbConnect function. table_name character, name table. id_quote_method character, used specify build SQLite columns' names using fields' identifiers read input file. details see description quote_method parameter format_column_names() function. Defaults DB_NAMES. col_names character vector, names columuns input file. Used override field names derived input file (using quote method selected id_quote_method). Must length number columns input file. NULL column names coming input file (quoting) used. Defaults NULL. col_types character vector classes assumed columns input file. Must length number columns input file. null, override data types guessed input file. NULL data type inferred input files used. Defaults NULL. col_import can either: numeric vector (coherced integers) columns' positions input file imported SQLite table; character vector columns' names imported. names input file (quoting id_quote_method), col_names NULL, expressed col_names vector. Defaults NULL, .e. columns imported. drop_table logical, TRUE target table dropped (exists) recreated importing data. FALSE, data input file appended existing table. Defaults FALSE. auto_pk logical, TRUE, pk_fields parameter NULL, additional column named SEQ added table defined INTEGER PRIMARY KEY (.e. effect alias ROWID). Defaults FALSE. build_pk logical, TRUE creates UNIQUE INDEX named <table_name>_PK defined combination fields specified pk_fields parameter. effective pk_fields null. Defaults FALSE. pk_fields character vector, list fields' names define UNIQUE INDEX. Defaults NULL. constant_values one row data frame whose columns added table database. additional table columns named data frame columns, corresponding values associeted record imported input file. useful keep track additional information (e.g., input file name, additional context data available data set, ...) loading content multiple input files table. Defults NULL.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromFeather.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a table from a Feather (Arrow IPC) file — dbTableFromFeather","text":"integer, number records table_name reading data input_file.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromView.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table in a SQLite database from a view — dbTableFromView","title":"Create a table in a SQLite database from a view — dbTableFromView","text":"dbTableFromView() function creates table SQLite database view already present database.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromView.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table in a SQLite database from a view — dbTableFromView","text":"","code":"dbTableFromView(   view_name,   dbcon,   table_name,   drop_table = FALSE,   build_pk = FALSE,   pk_fields = NULL )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromView.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table in a SQLite database from a view — dbTableFromView","text":"view_name character, name view. dbcon database connection, created dbConnect function. table_name character, name table. drop_table logical, TRUE target table dropped (exists) recreated importing data.  FALSE, data input file appended existing table. Defaults FALSE. build_pk logical, TRUE creates UNIQUE INDEX named <table_name>_PK defined combination fields specified pk_fields parameter. effective pk_fields null. Defaults FALSE. pk_fields character vector, list fields' names define UNIQUE INDEX. Defaults NULL.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromView.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a table in a SQLite database from a view — dbTableFromView","text":"integer, number records table_name writing data input view.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromXlsx.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table in a SQLite database from an Excel worksheet — dbTableFromXlsx","title":"Create a table in a SQLite database from an Excel worksheet — dbTableFromXlsx","text":"dbTableFromXlsx() function creates table SQLite database range Excel worksheet. dbTableFromXlsx() function reads data range Excel worksheet. table exist, create .","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromXlsx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table in a SQLite database from an Excel worksheet — dbTableFromXlsx","text":"","code":"dbTableFromXlsx(   input_file,   dbcon,   table_name,   sheet_name,   first_row,   cols_range,   header = TRUE,   id_quote_method = \"DB_NAMES\",   col_names = NULL,   col_types = NULL,   col_import = NULL,   drop_table = FALSE,   auto_pk = FALSE,   build_pk = FALSE,   pk_fields = NULL,   constant_values = NULL,   ... )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromXlsx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table in a SQLite database from an Excel worksheet — dbTableFromXlsx","text":"input_file character, file name (including path) read. dbcon database connection, created dbConnect function. table_name character, name table. sheet_name character, name worksheet containing data table. first_row integer, row number data table starts. present, row number header row, otherwise row number first row data. cols_range integer, numeric vector specifying columns worksheet read. header logical, TRUE first row contains fields' names. FALSE, column names column names Excel worksheet (.e. letters). id_quote_method character, used specify build SQLite columns' names using fields' identifiers read input file. details see description quote_method parameter format_column_names() function. Defautls DB_NAMES. col_names character vector, names columuns input file. Used override field names derived input file (using quote method selected id_quote_method). Must length number columns input file. NULL column names coming input file (quoting) used. Defaults NULL. col_types character vector classes assumed columns input file. Must length number columns input file. null, override data types guessed input file. NULL data type inferred input files used. Defaults NULL. col_import can either: numeric vector (coherced integers) columns' positions input file imported SQLite table; character vector columns' names imported. names input file (quoting id_quote_method), col_names NULL, expressed col_names vector. Defaults NULL, .e. columns imported. drop_table logical, TRUE target table dropped (exists) recreated importing data.  FALSE, data input file appended existing table. Defaults FALSE. auto_pk logical, TRUE, pk_fields parameter NULL, additional column named SEQ added table defined INTEGER PRIMARY KEY (.e. effect alias ROWID). Defaults FALSE. build_pk logical, TRUE creates UNIQUE INDEX named <table_name>_PK defined combination fields specified pk_fields parameter. effective pk_fields null. Defaults FALSE. pk_fields character vector, list fields' names define UNIQUE INDEX. Defults NULL. constant_values one row data frame whose columns added table database. additional table columns named data frame columns, corresponding values associeted record imported input file. useful keep track additional information (e.g., input file name, additional context data available data set, ...) loading content multiple input files table. Defults NULL. ... additional arguments passed openxlsx2::wb_to_df() function used read input data.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/dbTableFromXlsx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a table in a SQLite database from an Excel worksheet — dbTableFromXlsx","text":"integer, number records table_name reading data input_file.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/error_handler.html","id":null,"dir":"Reference","previous_headings":"","what":"error_handler manage error messages for package — error_handler","title":"error_handler manage error messages for package — error_handler","text":"error_handler manage error messages package","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/error_handler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"error_handler manage error messages for package — error_handler","text":"","code":"error_handler(err, fun, step)"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/error_handler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"error_handler manage error messages for package — error_handler","text":"err character, error message fun character, function name error happened step integer, code identifying step function error happened. dbTableFrom... functions steps : 101,121: read file schema (DSV, Xlsx) 102: handle col_names col_types 103: create empty table 104: read data 105: write data 106: indexing","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/error_handler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"error_handler manage error messages for package — error_handler","text":"nothing","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_dsv.html","id":null,"dir":"Reference","previous_headings":"","what":"Preview the table structure contained in a DSV file. — file_schema_dsv","title":"Preview the table structure contained in a DSV file. — file_schema_dsv","text":"file_schema_dsv() function returns data frame schema DSV file reading first max_lines delimiter separated values (DSV) text file infer column names data types (read full dataset memory). converts candidate data frame columns' names data types.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_dsv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preview the table structure contained in a DSV file. — file_schema_dsv","text":"","code":"file_schema_dsv(   input_file,   header = TRUE,   sep = \",\",   dec = \".\",   grp = \"\",   id_quote_method = \"DB_NAMES\",   max_lines = 2000,   null_columns = FALSE,   force_num_cols = TRUE,   ... )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_dsv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preview the table structure contained in a DSV file. — file_schema_dsv","text":"input_file character, file name (including path) read. header logical, TRUE first line contains fields' names. FALSE, column names formed sing \"V\" followed column number (specified utils::read.table()). sep character, field delimiter (e.g., \",\" CSV, \"\\t\" TSV) input file. Defaults \",\". dec character, decimal separator (e.g., \".\" \",\" depending locale) input file. Defaults \".\". grp character, character used digit grouping. defaults \"\" (.e. grouping). id_quote_method character, used specify build SQLite columns' names using fields' identifiers read input file. details see description quote_method parameter format_column_names() function. Defautls DB_NAMES. max_lines integer, number lines (excluding header) read infer columns' data types. Defaults 2000. null_columns logical, TRUE col_type columuns consisting NAs zero-length strings marked \"NULL\", otherwise marked character. Defaults FALSE force_num_cols logical, TRUE returned schema rows n_cols columns (.e. guessed number columns determined inspecting first max_lines lines input file), even rows input file fewer greater columns n_cols. FALSE tested lines number columns equal n_cols, function return list without schema element. defaults TRUE. ... Additional arguments quoting data interpretation described base::scan() function. parameters used file_schema_dsv : quote, character, set quoting characters. Defaults \"\" (.e., quoting). comment.char, character, comment character. Defaults \"\" (.e., comments). skip, integer, number lines skip reading data. Defaults 0. fileEncoding, character, name encoding input file. Defaults \"\". na.strings, character vector, strings interpreted NAs. Defaults c(\"NA\").","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_dsv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preview the table structure contained in a DSV file. — file_schema_dsv","text":"list following named elements: schema, data frame columns: col_names: columns' names, applying selected quote method; col_names_unquoted: columns' names, unquoted; id_quote_method set DB_NAMES col_names; quote methods unquoted versions col_names,generally src_names unless src_names contain quoting characters; col_types: columns' R data types; sql_types: columns' SQLite data types; src_names: columns' names appear input file. src_types: defaults text columns. src_is_quoted: logical vector indicating column least one value enclosed quotes. col_counts, data frame columns: num_col: number columns, Freq: number rows (within max_lines) number colums shown num_col. n_cols, integer, number columns selected file. num_col, vector integers length max_lines number detected columns row tested. col_fill, logical, set TRUE lines less columns n_cols. col_flush, logical, set TRUE lines columns n_cols.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_dsv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preview the table structure contained in a DSV file. — file_schema_dsv","text":"","code":"if (FALSE) { # \\dontrun{ file_schema_dsv(\"data.csv\", sep=\",\", dec=\".\", max_lines=50) file_schema_dsv(\"euro.csv\", sep=\";\", dec=\",\", header=FALSE) } # }"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_feather.html","id":null,"dir":"Reference","previous_headings":"","what":"Preview the table structure contained in a Feather file. — file_schema_feather","title":"Preview the table structure contained in a Feather file. — file_schema_feather","text":"file_schema_feather() function returns data frame schema Feather file. function used preview table structure contained Feather file, reading metadata file. inspects input file metadata read field identifiers' names data types, converts candidate data frame columns' names data types. dataset contained input file read memory, meta-data accessed.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_feather.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preview the table structure contained in a Feather file. — file_schema_feather","text":"","code":"file_schema_feather(input_file, id_quote_method = \"DB_NAMES\")"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_feather.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preview the table structure contained in a Feather file. — file_schema_feather","text":"input_file File name (including path) read id_quote_method character, used specify build SQLite columns' names using fields' identifiers read input file. details see description quote_method parameter format_column_names() function. Defaults DB_NAMES.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_feather.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preview the table structure contained in a Feather file. — file_schema_feather","text":"data frame columns: col_names: columns' names, applying selected quote method; col_names_unquoted: columns' names, unquoted; id_quote_method set DB_NAMES col_names; quote methods unquoted versions col_names, generally src_names unless src_names contain quoting characters; col_types: columns' R data types; sql_types: columns' SQLite data types; src_names: columns' names appear input file; src_types: Arrow's data type column.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_feather.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Preview the table structure contained in a Feather file. — file_schema_feather","text":"implementation based question Stackoverflow. # nolint: line_length_linter.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_xlsx.html","id":null,"dir":"Reference","previous_headings":"","what":"Preview the structure of a range of an Excel worksheet. — file_schema_xlsx","title":"Preview the structure of a range of an Excel worksheet. — file_schema_xlsx","text":"file_schema_xlsx() function returns data frame schema Excel data table. read range specified worksheet infer column names data types. converts candidate data frame columns' names data types.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_xlsx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preview the structure of a range of an Excel worksheet. — file_schema_xlsx","text":"","code":"file_schema_xlsx(   input_file,   sheet_name,   first_row,   cols_range,   header = TRUE,   id_quote_method = \"DB_NAMES\",   max_lines = 100,   null_columns = FALSE,   ... )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_xlsx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preview the structure of a range of an Excel worksheet. — file_schema_xlsx","text":"input_file character, file name (including path) read. sheet_name character, name worksheet containing data table. first_row integer, row number data table starts. present, row number header row, otherwise row number first row data. cols_range integer, numeric vector specifying columns worksheet read. header logical, TRUE first row contains fields' names. FALSE, column names column names Excel worksheet (.e. letters). id_quote_method character, used specify build SQLite columns' names using fields' identifiers read input file. details see description quote_method parameter format_column_names() function. Defaults DB_NAMES. max_lines integer, number lines (excluding header) read infer columns' data types. Defaults 100. null_columns logical, TRUE col_type columuns consisting NAs zero-length strings marked NA, otherwise marked character. Defaults FALSE ... Additional parameters passed openxlsx2::wb_to_df() function.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/file_schema_xlsx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preview the structure of a range of an Excel worksheet. — file_schema_xlsx","text":"data frame columns: col_names: columns' names, applying selected quote method; col_names_unquoted: columns' names, unquoted; id_quote_method set DB_NAMES col_names; quote methods unquoted versions col_names,generally src_names unless src_names contain quoting characters; col_types: columns' R data types; sql_types: columns' SQLite data types; src_names: columns' names appear input file; src_types: data type attribute column, determined openxlsx2::wb_to_df() function.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/format_column_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Format column names for SQLite — format_column_names","title":"Format column names for SQLite — format_column_names","text":"format_column_names() function formats vector strings used columns' names table SQLite database.","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/format_column_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format column names for SQLite — format_column_names","text":"","code":"format_column_names(   x,   quote_method = \"DB_NAMES\",   unique_names = TRUE,   encoding = \"\" )"},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/format_column_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format column names for SQLite — format_column_names","text":"x character vector identifiers' names quoted. quote_method character, used specify build SQLite columns' names identifiers passed x parameter. Supported values quote_method: DB_NAMES tries build valid SQLite column name: . substituting characters, letters digits _ character, _ character; b. prefixing N_ strings starting digit; c. prefixing F_ strings equal SQL92 keyword. SINGLE_QUOTES encloses string single quotes. SQL_SERVER encloses string square brackets. MYSQL encloses string back ticks. Defaults DB_NAMES. unique_names logical, checks duplicate name applying selected quote methods. duplicates exist, made unique adding postfix _[n], n progressive integer. Defaults TRUE. encoding character, encoding assumed input strings. used re-encode input order process build column identifiers. Defaults ‘\"\"’ (encoding current locale).","code":""},{"path":"https://fab-algo.github.io/RSQLite.toolkit/reference/format_column_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format column names for SQLite — format_column_names","text":"data frame containing columns' identifiers two formats: quoted: quoted names, per selected quote_method; unquoted: cleaned names, without quoting.","code":""}]
