---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# RSQLite.toolkit <a href="https://github.com/fab-algo/RSQLite.toolkit">
  <img src="man/figures/RSQLite.toolkit_logo.png" align="right" height="138" />
  </a>

<!-- badges: start -->
<!-- badges: end -->

RSQLite.toolkit is lightweight wrapper around the RSQLite package for
streamlined loading of data from **tabular files** (i.e. text delimited
files like CSV and TSV, Microsoft Excel, and Arrow IPC files) in
SQLite databases.

It includes also helper functions for inspecting the structure of the
input files, and some functions to simplify activities on the SQLite
tables.

## Installation

You can install the development version of RSQLite.toolkit
from [GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("fab-algo/RSQLite.toolkit")
```

## Examples

These basic examples show how to use the core functions of the package
to load example data in different tables in a test database:

```{r example, eval = TRUE}
library(RSQLite.toolkit)

dbcon <- dbConnect(RSQLite::SQLite(), file.path(tempdir(), "tests.sqlite"))

data_path <- system.file("extdata", package = "RSQLite.toolkit")

## creates the table ABALONE from a CSV file, adding the field 'SEQ' with the
## ROWID of each record through the use of the parameter 'auto_pk=TRUE'
dbTableFromDSV(input_file = file.path(data_path, "abalone.csv"),
               dbcon = dbcon, table_name = "ABALONE",
               drop_table = TRUE, auto_pk = TRUE,
               header = TRUE, sep = ",", dec = ".")

## creates table PORTFOLIO_PERF from Excel file, using the "all period" sheet
dbTableFromXlsx(input_file = file.path(data_path,
                                       "stock_portfolio.xlsx"),
                dbcon = dbcon, table_name = "PORTFOLIO_PERF",
                drop_table = TRUE,
                sheet_name = "all period", first_row = 2, cols_range = "A:S")

## creates table PENGUINS from Feather file
dbTableFromFeather(input_file = file.path(data_path, "penguins.feather"),
                   dbcon = dbcon, table_name = "PENGUINS",
                   drop_table = TRUE)

dbListTables(dbcon)

dbListFields(dbcon, "ABALONE")
dbListFields(dbcon, "PENGUINS")
dbListFields(dbcon, "PORTFOLIO_PERF")[1:5]

dbDisconnect(dbcon)
```

To inspect the structure of the input files, you can use the following functions:

```{r example2, eval = TRUE}
library(RSQLite.toolkit)

data_path <- system.file("extdata", package = "RSQLite.toolkit")

file_schema_dsv(input_file = file.path(data_path, "abalone.csv"),
                header = TRUE, sep = ",", dec = ".")$schema[, c(1, 3:7)]

file_schema_feather(input_file = file.path(data_path,
                                           "penguins.feather"))[, c(1, 3:6)]
```

## How to use the package

The basic idea behind this package is that storing all the data used throughout
a data‑analysis workflow in a database is a highly efficient and effective way
to manage information. The advantages of keeping raw data and their metadata
together in the same database—ideally under a shared data model—far outweigh
not only the additional overhead of maintaining a structured and centralized
system, but also the costs and complexity involved in importing information
from external files with disparate formats and conventions.

The purpose of this package is to reduce the burden of the last point (i.e.,
importing the data) as much as possible, through a set of function that

The core functions of the package are those that can be used to move data from
a file to a database table:

- `dbTableFromDSV()`
- `dbTableFromXlsx()`
- `dbTableFromFeather()`

All these functions share a common calling template that is outlined in the
following picture:

```{r, eval = TRUE, echo = FALSE, fig.align='center', out.width="100%"}
knitr::include_graphics("man/figures/README-dbTableFrom_template.png")
```

Be careful with default values, especially when importing form _delimiter separated
values_ text files: the default values for input data interpretation parameters
are seldom the right ones.

## Data sources

The example datasets, included in the `extdata` package directory, have been retrieved from
the following sources:

- `"abalone.csv"`: Predicting the age of abalone from physical measurements.
  Source link: <https://archive.ics.uci.edu/dataset/1/abalone>
- `"stock_portfolio.xlsx"`: Stock portfolio performance under a new weighted scoring
  stock selection model.
  Source link: <https://archive.ics.uci.edu/dataset/390/stock+portfolio+performance>
- `"penguins.feather"`: The Palmer Arcipelago's penguins data set.
  Source link: <https://allisonhorst.github.io/palmerpenguins/>.
  The "feather" file format of the dataset was downloaded from <https://github.com/lmassaron/datasets>.
